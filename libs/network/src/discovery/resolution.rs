//! Transport Resolution and Dynamic Reconfiguration
//!
//! Resolves optimal transport for actor communication and supports
//! hot-reload capabilities for actor placement without system restart.

use super::{nodes::ActorPlacement, Actor, Node, Result, TopologyConfig, TopologyError, Transport};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Instant;
use tokio::sync::RwLock;

/// Type alias for actor runtime information mapping
type ActorRuntimesMap = Arc<RwLock<HashMap<String, ActorRuntimeInfo>>>;

/// Type alias for node transport mapping
type NodeTransportMap = HashMap<(String, String), Transport>;

/// Type alias for actor channel mapping
type ActorChannelMap = HashMap<(String, String), ChannelInfo>;

/// Type alias for health data mapping
type HealthDataMap = Arc<RwLock<HashMap<String, ActorHealth>>>;

/// Type alias for circuit breaker mapping
type CircuitBreakerMap = Arc<RwLock<HashMap<String, CircuitBreaker>>>;

/// Resolves transport configuration and manages dynamic reconfiguration
pub struct TopologyResolver {
    config: Arc<RwLock<TopologyConfig>>,
    actor_runtimes: ActorRuntimesMap,
    transport_graph: Arc<RwLock<TransportGraph>>,
    health_monitor: Arc<ActorHealthMonitor>,
}

/// Actor runtime information with health monitoring
#[derive(Debug, Clone)]
pub struct ActorRuntimeInfo {
    pub actor_id: String,
    pub node_id: String,
    pub placement: ActorPlacement,
    pub status: ActorStatus,
    pub health: ActorHealth,
    pub start_time: Instant,
    pub last_migration: Option<Instant>,
}

/// Comprehensive actor health metrics
#[derive(Debug, Clone)]
pub struct ActorHealth {
    pub message_processing_rate: f64,
    pub error_rate: f64,
    pub memory_usage_mb: usize,
    pub cpu_usage_percent: f64,
    pub last_heartbeat: Instant,
    pub circuit_breaker_state: CircuitBreakerState,
    pub latency_percentiles: LatencyMetrics,
}

#[derive(Debug, Clone)]
pub enum CircuitBreakerState {
    Closed,
    Open { since: Instant },
    HalfOpen { test_count: u32 },
}

#[derive(Debug, Clone, Default)]
pub struct LatencyMetrics {
    pub p50_ms: f64,
    pub p95_ms: f64,
    pub p99_ms: f64,
    pub max_ms: f64,
}

#[derive(Debug, Clone)]
pub enum ActorStatus {
    Starting,
    Running,
    Migrating { from_node: String, to_node: String },
    Stopping,
    Stopped,
    Failed { reason: String, recoverable: bool },
}

/// Transport graph for routing optimization
#[derive(Debug, Clone)]
#[allow(dead_code)]
pub struct TransportGraph {
    /// Node-to-node transport configurations
    node_transports: NodeTransportMap,
    /// Actor-to-actor communication channels
    actor_channels: ActorChannelMap,
    /// Performance characteristics
    performance_cache: HashMap<String, TransportPerformance>,
}

#[derive(Debug, Clone)]
pub struct ChannelInfo {
    pub channel_name: String,
    pub transport: Transport,
    pub message_count: u64,
    pub bytes_transferred: u64,
    pub last_activity: Instant,
}

#[derive(Debug, Clone)]
pub struct TransportPerformance {
    pub latency_ms: f64,
    pub bandwidth_mbps: f64,
    pub error_rate: f64,
    pub last_measured: Instant,
}

/// Actor health monitoring service
pub struct ActorHealthMonitor {
    health_data: HealthDataMap,
    circuit_breakers: CircuitBreakerMap,
}

/// Circuit breaker for actor health management
#[derive(Debug, Clone)]
#[allow(dead_code)]
pub struct CircuitBreaker {
    failure_threshold: u32,
    success_threshold: u32,
    timeout_duration: std::time::Duration,
    state: CircuitBreakerState,
    failure_count: u32,
    success_count: u32,
}

// =============================================================================
// FUTURE: EVENT-DRIVEN SERVICE DISCOVERY
// =============================================================================

/// Future service discovery architecture for autonomous system activation
///
/// **Current State**: Manual service startup with hardcoded connections
/// **Future Vision**: Services announce capabilities and auto-discover dependencies
///
/// ## Event-Driven Activation Pattern
///
/// ```rust
/// // Services announce their capabilities to topology resolver
/// polygon.announce("produces: market_data.polygon.dex_events");
/// relay.announce("consumes: market_data.*, produces: signals.arbitrage");
/// strategy.announce("consumes: signals.arbitrage, produces: execution.orders");
///
/// // System self-assembles through topology resolver
/// let relay_endpoint = resolver.discover_consumers("market_data.polygon.*")?;
/// let strategy_endpoints = resolver.discover_consumers("signals.arbitrage")?;
///
/// // Automatic transport selection based on actor placement
/// let transport = resolver.optimal_transport("polygon", "market_data_relay")?;
/// match transport {
///     Transport::UnixSocket(path) => connect_local(path),
///     Transport::SharedMemory(channel) => connect_shm(channel),
///     Transport::Network(endpoint) => connect_tcp(endpoint),
/// }
/// ```
///
/// ## Organic System Growth
///
/// **Startup Sequence** (no hardcoded ordering):
/// 1. `polygon` starts → announces "produces: market_data.polygon.*"
/// 2. `topology_resolver` sees unrouted data → spawns `market_data_relay`
/// 3. `market_data_relay` starts → announces "consumes: market_data.*"
/// 4. `polygon` discovers relay → establishes connection → data flows
/// 5. `arbitrage_strategy` starts → discovers relay → subscribes to signals
/// 6. System reaches steady state through organic connection formation
///
/// **Benefits**:
/// - **Zero configuration**: No hardcoded connection paths
/// - **Fault tolerance**: Dead services auto-discovered and replaced
/// - **Load balancing**: Multiple instances of same service auto-discovered
/// - **A/B testing**: Run parallel service versions, compare performance
///
/// ## Implementation Requirements
///
/// **Service Registration API**:
/// ```rust
/// trait ServiceDiscovery {
///     async fn announce(&self, capabilities: &str) -> Result<()>;
///     async fn discover(&self, pattern: &str) -> Result<Vec<ServiceEndpoint>>;
///     async fn watch(&self, pattern: &str) -> Result<ServiceStream>;
/// }
/// ```
///
/// **Topology Integration**:
/// - Extend `TopologyResolver` with dynamic service registry
/// - Add capability-based routing to `TransportGraph`
/// - Implement auto-spawning via `DeploymentEngine`
///
/// **Message Bus Evolution**:
/// Current: Hardcoded Unix sockets between known services
/// Future: Capability-driven routing with automatic endpoint resolution
///
/// ```rust
/// // Current: Hardcoded
/// RelayOutput::new("/tmp/torq/market_data.sock", RelayDomain::MarketData)
///
/// // Future: Discovery-driven
/// let endpoints = resolver.discover("consumes:market_data.*")?;
/// RelayOutput::new_discoverable(endpoints, RelayDomain::MarketData)
/// ```
pub struct FutureServiceDiscovery;

impl TopologyResolver {
    pub fn new(config: TopologyConfig) -> Self {
        Self {
            config: Arc::new(RwLock::new(config)),
            actor_runtimes: Arc::new(RwLock::new(HashMap::new())),
            transport_graph: Arc::new(RwLock::new(TransportGraph::new())),
            health_monitor: Arc::new(ActorHealthMonitor::new()),
        }
    }

    /// Resolve optimal transport for actor communication
    pub async fn resolve_transport(&self, from_actor: &str, to_actor: &str) -> Result<Transport> {
        let config = self.config.read().await;

        let from_node = self.find_actor_node(&config, from_actor).ok_or_else(|| {
            TopologyError::ActorNotFound {
                actor: from_actor.to_string(),
            }
        })?;

        let to_node = self.find_actor_node(&config, to_actor).ok_or_else(|| {
            TopologyError::ActorNotFound {
                actor: to_actor.to_string(),
            }
        })?;

        if from_node == to_node {
            // Same node - use shared memory
            self.resolve_shared_memory_transport(&config, &from_node, from_actor, to_actor)
                .await
        } else {
            // Different nodes - use network
            self.resolve_network_transport(&config, &from_node, &to_node)
                .await
        }
    }

    /// Dynamic actor migration without system restart
    pub async fn migrate_actor(&mut self, actor_id: &str, target_node: &str) -> Result<()> {
        tracing::info!(
            "Starting migration of actor '{}' to node '{}'",
            actor_id,
            target_node
        );

        // 1. Validate migration is possible
        self.validate_migration(actor_id, target_node).await?;

        // 2. Update actor status to migrating
        self.update_actor_status(
            actor_id,
            ActorStatus::Migrating {
                from_node: self.get_actor_node(actor_id).ok_or_else(|| {
                    TopologyError::ActorNotFound {
                        actor: actor_id.to_string(),
                    }
                })?,
                to_node: target_node.to_string(),
            },
        )
        .await?;

        // 3. Drain in-flight messages
        self.drain_actor_channels(actor_id).await?;

        // 4. Stop actor on source node
        self.stop_actor_gracefully(actor_id).await?;

        // 5. Update configuration
        self.update_actor_placement(actor_id, target_node).await?;

        // 6. Start actor on target node
        self.start_actor_on_node(actor_id, target_node).await?;

        // 7. Re-establish transport channels
        self.rebuild_transport_graph().await?;

        // 8. Update status to running
        self.update_actor_status(actor_id, ActorStatus::Running)
            .await?;

        tracing::info!(
            "Successfully migrated actor '{}' to node '{}'",
            actor_id,
            target_node
        );
        Ok(())
    }

    /// Hot-reload topology configuration
    pub async fn reload_configuration(&mut self, new_config: TopologyConfig) -> Result<()> {
        tracing::info!("Reloading topology configuration");

        // Validate new configuration
        new_config.validate()?;

        let old_config = self.config.read().await.clone();

        // Calculate differences
        let changes = self
            .calculate_config_changes(&old_config, &new_config)
            .await?;

        // Apply changes gradually
        self.apply_configuration_changes(changes).await?;

        // Update configuration
        *self.config.write().await = new_config;

        tracing::info!("Successfully reloaded topology configuration");
        Ok(())
    }

    /// Get current actor health metrics
    /// Get actor by ID
    pub fn get_actor(&self, actor_id: &str) -> Option<Actor> {
        tokio::runtime::Handle::current().block_on(async {
            let config = self.config.read().await;
            config.actors.get(actor_id).cloned()
        })
    }

    /// Get node ID where actor is placed
    pub fn get_actor_node(&self, actor_id: &str) -> Option<String> {
        tokio::runtime::Handle::current()
            .block_on(async { self.get_actor_node_async(actor_id).await.ok() })
    }

    /// Get node object where actor is placed
    pub fn get_actor_node_object(&self, actor_id: &str) -> Option<Node> {
        tokio::runtime::Handle::current().block_on(async {
            let config = self.config.read().await;
            if let Some(node_id) = self.find_actor_node(&config, actor_id) {
                config.nodes.get(&node_id).cloned()
            } else {
                None
            }
        })
    }

    /// Get actor placement information
    pub fn get_actor_placement(&self, actor_id: &str) -> Option<ActorPlacement> {
        tokio::runtime::Handle::current().block_on(async {
            let config = self.config.read().await;
            config.actors.get(actor_id).and_then(|_actor| {
                // Find the placement in the node that contains this actor
                for node in config.nodes.values() {
                    if let Some(placement) = node.actor_placements.get(actor_id) {
                        return Some(placement.clone());
                    }
                }
                None
            })
        })
    }

    pub async fn get_actor_health(&self, actor_id: &str) -> Option<ActorHealth> {
        self.health_monitor.get_health(actor_id).await
    }

    /// Get all actor health metrics
    pub async fn get_all_actor_health(&self) -> HashMap<String, ActorHealth> {
        self.health_monitor.get_all_health().await
    }

    /// Trigger circuit breaker for unhealthy actor
    pub async fn trigger_circuit_breaker(&self, actor_id: &str, reason: String) -> Result<()> {
        self.health_monitor
            .trigger_circuit_breaker(actor_id, reason)
            .await
    }

    /// Auto-scaling based on load and health metrics
    pub async fn auto_scale(&mut self) -> Result<Vec<ScalingAction>> {
        let mut actions = Vec::new();
        let health_data = self.get_all_actor_health().await;

        for (actor_id, health) in health_data {
            // Check if actor needs scaling up
            if health.cpu_usage_percent > 90.0 && health.error_rate < 0.01 {
                // High CPU, low error rate - consider horizontal scaling
                actions.push(ScalingAction::ScaleUp {
                    actor_id: actor_id.clone(),
                    reason: "High CPU usage".to_string(),
                });
            }

            // Check if actor needs migration due to poor performance
            if health.latency_percentiles.p95_ms > 100.0 || health.error_rate > 0.05 {
                // High latency or error rate - consider migration
                actions.push(ScalingAction::Migrate {
                    actor_id: actor_id.clone(),
                    target_node: self.find_best_node_for_actor(&actor_id).await?,
                    reason: "Performance degradation".to_string(),
                });
            }

            // Check circuit breaker state
            if matches!(
                health.circuit_breaker_state,
                CircuitBreakerState::Open { .. }
            ) {
                actions.push(ScalingAction::Recover {
                    actor_id: actor_id.clone(),
                    action: RecoveryAction::Restart,
                    reason: "Circuit breaker open".to_string(),
                });
            }
        }

        Ok(actions)
    }

    // Implementation methods

    async fn resolve_shared_memory_transport(
        &self,
        config: &TopologyConfig,
        node_id: &str,
        from_actor: &str,
        to_actor: &str,
    ) -> Result<Transport> {
        let node = config
            .nodes
            .get(node_id)
            .ok_or_else(|| TopologyError::NodeNotFound {
                node: node_id.to_string(),
            })?;

        // Find shared channel between actors
        let from_actor_def = config.actors.get(from_actor).unwrap();
        let to_actor_def = config.actors.get(to_actor).unwrap();

        // Find common channel
        for output_channel in &from_actor_def.outputs {
            if to_actor_def.inputs.contains(output_channel) {
                if let Some(channel_config) = node.local_channels.get(output_channel) {
                    return Ok(Transport::shared_memory(
                        output_channel.clone(),
                        channel_config.numa_node,
                    ));
                }
            }
        }

        Err(TopologyError::TransportResolution {
            reason: format!(
                "No shared channel found between {} and {}",
                from_actor, to_actor
            ),
        })
    }

    async fn resolve_network_transport(
        &self,
        config: &TopologyConfig,
        from_node: &str,
        to_node: &str,
    ) -> Result<Transport> {
        // Check for explicit inter-node route
        if let Some(inter_node) = &config.inter_node {
            for route in &inter_node.routes {
                if (route.source_node == from_node && route.target_node == to_node)
                    || (route.source_node == to_node && route.target_node == from_node)
                {
                    let mut transport =
                        Transport::network(from_node.to_string(), to_node.to_string());

                    // Apply route-specific overrides
                    if let Transport::Network {
                        ref mut protocol,
                        ref mut routing,
                        ..
                    } = transport
                    {
                        if let Some(override_protocol) = &route.transport_override {
                            *protocol = override_protocol.clone();
                        }

                        if let Some(bandwidth) = route.bandwidth_limit_mbps {
                            routing.bandwidth_mbps = Some(bandwidth);
                        }

                        if let Some(latency) = route.latency_target_ms {
                            routing.latency_ms = Some(latency);
                        }
                    }

                    return Ok(transport);
                }
            }
        }

        // Use default network transport
        Ok(Transport::network(
            from_node.to_string(),
            to_node.to_string(),
        ))
    }

    async fn validate_migration(&self, actor_id: &str, target_node: &str) -> Result<()> {
        let config = self.config.read().await;

        // Check target node exists
        let target_node_config =
            config
                .nodes
                .get(target_node)
                .ok_or_else(|| TopologyError::NodeNotFound {
                    node: target_node.to_string(),
                })?;

        // Check actor exists
        let actor = config
            .actors
            .get(actor_id)
            .ok_or_else(|| TopologyError::ActorNotFound {
                actor: actor_id.to_string(),
            })?;

        // Check resource availability
        let required_cores = 1; // TODO: get from actor requirements
        let required_memory = actor.resources.min_memory_mb;

        if !target_node_config.has_capacity_for(required_cores, required_memory) {
            return Err(TopologyError::ResourceConstraint {
                message: format!(
                    "Target node '{}' lacks capacity for actor '{}'",
                    target_node, actor_id
                ),
            });
        }

        Ok(())
    }

    async fn drain_actor_channels(&self, actor_id: &str) -> Result<()> {
        // Implementation would depend on message bus integration
        tracing::info!("Draining channels for actor '{}'", actor_id);

        // Give some time for in-flight messages to complete
        tokio::time::sleep(std::time::Duration::from_millis(100)).await;

        Ok(())
    }

    async fn stop_actor_gracefully(&self, actor_id: &str) -> Result<()> {
        tracing::info!("Stopping actor '{}' gracefully", actor_id);

        // Implementation would send shutdown signal to actor
        // and wait for graceful termination

        Ok(())
    }

    async fn update_actor_placement(&self, actor_id: &str, target_node: &str) -> Result<()> {
        let mut config = self.config.write().await;

        // Remove from old node
        for node in config.nodes.values_mut() {
            node.actor_placements.remove(actor_id);
        }

        // Add to new node
        if let Some(target_node_config) = config.nodes.get_mut(target_node) {
            target_node_config.actor_placements.insert(
                actor_id.to_string(),
                super::nodes::ActorPlacement::default(), // Use default placement
            );
        }

        Ok(())
    }

    async fn start_actor_on_node(&self, actor_id: &str, node_id: &str) -> Result<()> {
        tracing::info!("Starting actor '{}' on node '{}'", actor_id, node_id);

        // Implementation would start actor process on target node

        Ok(())
    }

    async fn rebuild_transport_graph(&self) -> Result<()> {
        tracing::info!("Rebuilding transport graph");

        let mut graph = self.transport_graph.write().await;

        // Recalculate all transports based on new configuration
        // This would be expensive in a real system and might be optimized
        // to only update affected routes

        *graph = TransportGraph::new();

        Ok(())
    }

    async fn update_actor_status(&self, actor_id: &str, status: ActorStatus) -> Result<()> {
        let mut runtimes = self.actor_runtimes.write().await;

        if let Some(runtime_info) = runtimes.get_mut(actor_id) {
            runtime_info.status = status;
        }

        Ok(())
    }

    async fn get_actor_node_async(&self, actor_id: &str) -> Result<String> {
        let config = self.config.read().await;
        self.find_actor_node(&config, actor_id)
            .ok_or_else(|| TopologyError::ActorNotFound {
                actor: actor_id.to_string(),
            })
    }

    fn find_actor_node(&self, config: &TopologyConfig, actor_id: &str) -> Option<String> {
        for (node_id, node) in &config.nodes {
            if node.actor_placements.contains_key(actor_id) {
                return Some(node_id.clone());
            }
        }
        None
    }

    async fn calculate_config_changes(
        &self,
        old_config: &TopologyConfig,
        new_config: &TopologyConfig,
    ) -> Result<Vec<ConfigChange>> {
        let mut changes = Vec::new();

        // Compare actor placements
        for actor_id in new_config.actors.keys() {
            let old_node = self.find_actor_node(old_config, actor_id);
            let new_node = self.find_actor_node(new_config, actor_id);

            match (old_node, new_node) {
                (Some(old), Some(new)) if old != new => {
                    changes.push(ConfigChange::ActorMigration {
                        actor_id: actor_id.clone(),
                        from_node: old,
                        to_node: new,
                    });
                }
                (None, Some(new)) => {
                    changes.push(ConfigChange::ActorAdded {
                        actor_id: actor_id.clone(),
                        node_id: new,
                    });
                }
                (Some(old), None) => {
                    changes.push(ConfigChange::ActorRemoved {
                        actor_id: actor_id.clone(),
                        node_id: old,
                    });
                }
                _ => {} // No change
            }
        }

        Ok(changes)
    }

    async fn apply_configuration_changes(&mut self, changes: Vec<ConfigChange>) -> Result<()> {
        for change in changes {
            match change {
                ConfigChange::ActorMigration {
                    actor_id, to_node, ..
                } => {
                    self.migrate_actor(&actor_id, &to_node).await?;
                }
                ConfigChange::ActorAdded { actor_id, node_id } => {
                    self.start_actor_on_node(&actor_id, &node_id).await?;
                }
                ConfigChange::ActorRemoved { actor_id, .. } => {
                    self.stop_actor_gracefully(&actor_id).await?;
                }
            }
        }

        Ok(())
    }

    async fn find_best_node_for_actor(&self, _actor_id: &str) -> Result<String> {
        let config = self.config.read().await;

        // Simple heuristic: find node with lowest CPU usage
        // In a real system, this would consider many factors
        let mut best_node = None;
        let mut best_usage = f64::MAX;

        for node_id in config.nodes.keys() {
            // Get node CPU usage (mock implementation)
            let usage = 50.0; // Would get real metrics

            if usage < best_usage {
                best_usage = usage;
                best_node = Some(node_id.clone());
            }
        }

        best_node.ok_or_else(|| TopologyError::NodeNotFound {
            node: "any available node".to_string(),
        })
    }
}

/// Configuration change types for hot-reload
#[derive(Debug, Clone)]
pub enum ConfigChange {
    ActorMigration {
        actor_id: String,
        from_node: String,
        to_node: String,
    },
    ActorAdded {
        actor_id: String,
        node_id: String,
    },
    ActorRemoved {
        actor_id: String,
        node_id: String,
    },
}

/// Auto-scaling actions
#[derive(Debug, Clone)]
pub enum ScalingAction {
    ScaleUp {
        actor_id: String,
        reason: String,
    },
    ScaleDown {
        actor_id: String,
        reason: String,
    },
    Migrate {
        actor_id: String,
        target_node: String,
        reason: String,
    },
    Recover {
        actor_id: String,
        action: RecoveryAction,
        reason: String,
    },
}

#[derive(Debug, Clone)]
pub enum RecoveryAction {
    Restart,
    Migrate,
    ReplaceWithBackup,
}

impl TransportGraph {
    fn new() -> Self {
        Self {
            node_transports: HashMap::new(),
            actor_channels: HashMap::new(),
            performance_cache: HashMap::new(),
        }
    }
}

impl ActorHealthMonitor {
    fn new() -> Self {
        Self {
            health_data: Arc::new(RwLock::new(HashMap::new())),
            circuit_breakers: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    async fn get_health(&self, actor_id: &str) -> Option<ActorHealth> {
        self.health_data.read().await.get(actor_id).cloned()
    }

    async fn get_all_health(&self) -> HashMap<String, ActorHealth> {
        self.health_data.read().await.clone()
    }

    async fn trigger_circuit_breaker(&self, actor_id: &str, reason: String) -> Result<()> {
        let mut breakers = self.circuit_breakers.write().await;

        if let Some(breaker) = breakers.get_mut(actor_id) {
            breaker.record_failure();
        } else {
            // Create new circuit breaker
            let mut breaker = CircuitBreaker::new();
            breaker.record_failure();
            breakers.insert(actor_id.to_string(), breaker);
        }

        tracing::warn!(
            "Circuit breaker triggered for actor '{}': {}",
            actor_id,
            reason
        );
        Ok(())
    }
}

#[allow(dead_code)]
impl CircuitBreaker {
    fn new() -> Self {
        Self {
            failure_threshold: 5,
            success_threshold: 2,
            timeout_duration: std::time::Duration::from_secs(60),
            state: CircuitBreakerState::Closed,
            failure_count: 0,
            success_count: 0,
        }
    }

    fn record_failure(&mut self) {
        self.failure_count += 1;

        if self.failure_count >= self.failure_threshold {
            self.state = CircuitBreakerState::Open {
                since: Instant::now(),
            };
        }
    }

    fn record_success(&mut self) {
        match self.state {
            CircuitBreakerState::HalfOpen { .. } => {
                self.success_count += 1;
                if self.success_count >= self.success_threshold {
                    self.state = CircuitBreakerState::Closed;
                    self.failure_count = 0;
                    self.success_count = 0;
                }
            }
            CircuitBreakerState::Closed => {
                self.failure_count = 0;
            }
            _ => {}
        }
    }

    fn can_execute(&mut self) -> bool {
        match &self.state {
            CircuitBreakerState::Closed => true,
            CircuitBreakerState::Open { since } => {
                if since.elapsed() >= self.timeout_duration {
                    self.state = CircuitBreakerState::HalfOpen { test_count: 0 };
                    true
                } else {
                    false
                }
            }
            CircuitBreakerState::HalfOpen { test_count } => {
                *test_count < 1 // Allow one test call
            }
        }
    }
}
